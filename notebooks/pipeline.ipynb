{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmfewshot\n",
    "import mmdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots = [5]\n",
    "xml_path = \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/data/VOCdevkit/VOC2012/Annotations\"\n",
    "image_xml_path = \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/data/VOCdevkit/VOC2012/JPEGImages\"\n",
    "few_shot_ann_path = \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/data/few_shot_ann/voc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def get_xml_content(cat, img_path, x1, y1, x2, y2):\n",
    "  img_name = img_path.split(\"/\")[-1]\n",
    "  img = Image.open(img_path)\n",
    "  w, h = img.size\n",
    "  content = f'''\n",
    "<annotation>\n",
    "<filename>{img_name}</filename>\n",
    "<folder>VOC2012</folder>\n",
    "<object>\n",
    "  <name>{cat}</name>\n",
    "  <actions>\n",
    "    <jumping>0</jumping>\n",
    "    <other>1</other>\n",
    "    <phoning>0</phoning>\n",
    "    <playinginstrument>0</playinginstrument>\n",
    "    <reading>0</reading>\n",
    "    <ridingbike>0</ridingbike>\n",
    "    <ridinghorse>0</ridinghorse>\n",
    "    <running>0</running>\n",
    "    <takingphoto>0</takingphoto>\n",
    "    <usingcomputer>0</usingcomputer>\n",
    "    <walking>0</walking>\n",
    "  </actions>\n",
    "  <bndbox>\n",
    "    <xmax>{x2}</xmax>\n",
    "    <xmin>{x1}</xmin>\n",
    "    <ymax>{y2}</ymax>\n",
    "    <ymin>{y1}</ymin>\n",
    "  </bndbox>\n",
    "  <difficult>0</difficult>\n",
    "  <pose>Unspecified</pose>\n",
    "  <point>\n",
    "    <x>308</x>\n",
    "    <y>189</y>\n",
    "  </point>\n",
    "</object>\n",
    "<segmented>0</segmented>\n",
    "<size>\n",
    "  <depth>3</depth>\n",
    "  <height>{h}</height>\n",
    "  <width>{w}</width>\n",
    "</size>\n",
    "<source>\n",
    "  <annotation>PASCAL VOC2012</annotation>\n",
    "  <database>The VOC2012 Database</database>\n",
    "  <image>flickr</image>\n",
    "</source>\n",
    "</annotation>\n",
    "  '''.strip()\n",
    "  return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmdet\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def get_bb_contour(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    th, threshed = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    ## (2) Morph-op to remove noise\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
    "    morphed = cv2.morphologyEx(threshed, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    ## (3) Find the max-area contour\n",
    "    cnts = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    cnt = sorted(cnts, key=cv2.contourArea)[-1]\n",
    "\n",
    "    ## (4) Crop and save it\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    return x, y, x+w, y+h\n",
    "\n",
    "def get_bb_full_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    return 1, 1, img.shape[1], img.shape[0]\n",
    "\n",
    "def get_max_object(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    th, threshed = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    ## (2) Morph-op to remove noise\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
    "    morphed = cv2.morphologyEx(threshed, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    ## (3) Find the max-area contour\n",
    "    cnts = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    x1 = []\n",
    "    y1 = []\n",
    "    x2 = []\n",
    "    y2 = []\n",
    "    for cnt in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        x1.append(x)\n",
    "        y1.append(y)\n",
    "        x2.append(x+w)\n",
    "        y2.append(y+h)\n",
    "    x1 = min(x1)\n",
    "    y1 = min(y1)\n",
    "    x2 = max(x2)\n",
    "    y2 = max(y2)\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "\n",
    "def create_annotations_and_label_images(cat, query_image_path,\n",
    "                                        label_image_path,\n",
    "                                        ):\n",
    "    color = (0, 0, 255)\n",
    "    thickness = 2\n",
    "    if not os.path.exists(os.path.join(label_image_path, \"img_with_bbox\")):\n",
    "        os.makedirs(os.path.join(label_image_path, \"img_with_bbox\"))\n",
    "\n",
    "    for idx, img_name in enumerate(os.listdir(query_image_path)):\n",
    "        img_path = os.path.join(query_image_path, img_name)\n",
    "        # x1, y1, x2, y2 = get_bb_contour(img_path)\n",
    "        x1, y1, x2, y2 = get_max_object(img_path)\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
    "        new_name = img_name.split(\".\")[0] + \"_bbox.\" + img_name.split(\".\")[1]\n",
    "        new_img_path = os.path.join(label_image_path, \"img_with_bbox\", new_name)\n",
    "        cv2.imwrite(new_img_path, img)\n",
    "        xml_content = get_xml_content(cat, img_path, x1, y1, x2, y2)\n",
    "        xml_name = img_name.split(\".\")[0]\n",
    "        if os.path.exists(os.path.join(xml_path, xml_name + \".xml\")):\n",
    "            os.remove(os.path.join(xml_path, xml_name + \".xml\"))\n",
    "        f = open(os.path.join(xml_path, xml_name + \".txt\"), 'w')\n",
    "        f.write(xml_content)\n",
    "        f.close()\n",
    "        os.rename(os.path.join(xml_path, xml_name + \".txt\"), os.path.join(xml_path, xml_name + \".xml\"))\n",
    "        \n",
    "        shutil.copy(os.path.join(query_image_path, img_name), os.path.join(image_xml_path, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_category(cat):\n",
    "    with open('/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/mmfewshot/detection/datasets/voc.py', 'r') as file:\n",
    "        file_content = file.readlines()\n",
    "\n",
    "    file_content[23] = f\"\\t\\t\\t\\t\\t'pottedplant', 'sheep', 'train', 'tvmonitor', '{cat}'),\\n\"\n",
    "    file_content[33] = f\"\\tNOVEL_CLASSES_SPLIT1=('{cat}',),\\n\"\n",
    "\n",
    "    with open('/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/mmfewshot/detection/datasets/voc.py', 'w') as file:\n",
    "        file.writelines(file_content)\n",
    "    print(file_content[33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_image_to_txt_path(cat, query_image_path):\n",
    "  for shot in shots:\n",
    "      if (len(os.listdir(query_image_path))) < shot:\n",
    "          print(f\"[INFO] not enough image for {shot} shot\")\n",
    "          break\n",
    "      print(shot)\n",
    "      f = open(os.path.join(few_shot_ann_path, f\"benchmark_{str(shot)}shot/box_{str(shot)}shot_{cat}_train.txt\"), \"w\")\n",
    "      for img_name in os.listdir(query_image_path)[:shot]:\n",
    "        f.write(f\"VOC2012/JPEGImages/{img_name}\\n\")\n",
    "      f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "data_dict = [\n",
    "    # {\n",
    "    #     'cat': '3326',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3326/focus_3326\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3326/3326\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3326/\",\n",
    "    # },\n",
    "    # {\n",
    "    #     'cat': '3191',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3191/focus_3191\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3191/3191\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3191/\",\n",
    "    # },\n",
    "    # {\n",
    "    #     'cat': 'door_focus_5_no_background',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/img/focus_door/no_background\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/img/door\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/img/\",\n",
    "    # },\n",
    "    # {\n",
    "    #     'cat': 'kettlebell',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/image/KETTLEBELL/focus_Kettlebell\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/image/KETTLEBELL/Kettlebell\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/image/KETTLEBELL/\",\n",
    "    # },\n",
    "    # {\n",
    "    #     'cat': '3190',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3190/focus_3190\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3190/3190\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3190/\",\n",
    "    # },\n",
    "    # {\n",
    "    #     'cat': '2930',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/2930/focus_2930\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/2930/2930\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/2930/\",\n",
    "    # },\n",
    "    # {\n",
    "    #     'cat': '2864',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/2864/focus_2864\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/2864/2864\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/2864/\",\n",
    "    # },\n",
    "    # {\n",
    "    #     'cat': '3264',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3264/focus_3264\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3264/3264\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3264/\",\n",
    "    # },\n",
    "    # {\n",
    "    #     'cat': 'papasan',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/image/GAR-514/focus_GAR514\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/image/GAR-514/GAR514\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/image/GAR-514\",\n",
    "    # },\n",
    "    # {\n",
    "    #     'cat': 'tv_stand',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/2052/focus_2052\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/2052/2052\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/2052\",\n",
    "    # },\n",
    "    # {\n",
    "    #     'cat': 'tv_stand_2053',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/2053/focus_2053\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/2053/2053\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/2053\",\n",
    "    # },\n",
    "    # {\n",
    "    #     'cat': '3884',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3884/focus_3884\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3884/3884\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3884\",\n",
    "    # },\n",
    "    # {\n",
    "    #     'cat': '3883',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3883/focus_3883\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3883/3883\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3883\",\n",
    "    # },\n",
    "    # {\n",
    "    #     'cat': '3848',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3848/focus_3848\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3848/3848\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3848\",\n",
    "    # },\n",
    "    # {\n",
    "    #     'cat': '3963',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3963/focus_3963/focus_1\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3963/3963\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3963\",\n",
    "    # },\n",
    "    # {\n",
    "    #     'cat': '3865',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3865/focus_1\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3865/3865\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3865\",\n",
    "    # },\n",
    "    # {\n",
    "    #     'cat': '3846',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3846/focus_1\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3846/3846\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3846\",\n",
    "    # },\n",
    "    # {\n",
    "    #     'cat': '3771',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3771/focus_3771\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3771/3771\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3771\",\n",
    "    # },\n",
    "    # {\n",
    "    #     'cat': '2030',\n",
    "    #     'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/2030/focus_2030\",\n",
    "    #     'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/2030/2030\",\n",
    "    #     'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/2030\",\n",
    "    # },\n",
    "    {\n",
    "        'cat': '3848',\n",
    "        'query_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3848/focus_3848\",\n",
    "        'database_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3848/3848\",\n",
    "        'label_image_path': \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/3848\",\n",
    "    },\n",
    "]\n",
    "\n",
    "work_dir = \"work_dirs/additional_focus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data  3848 ...\n",
      "\tNOVEL_CLASSES_SPLIT1=('3848',),\n",
      "\n",
      "5\n",
      "CUDA_VISIBLE_DEVICES=0 python tools/detection/train.py configs/detection/attention_rpn/voc/split1/attention-rpn_r50_c4_voc-split1_5shot-fine-tuning.py --work-dir work_dirs/additional_focus/3848 --no-validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 14:17:16,557 - mmfewshot - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]\n",
      "CUDA available: True\n",
      "GPU 0: NVIDIA GeForce RTX 3060\n",
      "CUDA_HOME: /usr/local/cuda-11.8\n",
      "NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
      "PyTorch: 2.0.0+cu118\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.6\n",
      "    - Built with CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "TorchVision: 0.15.1+cu118\n",
      "OpenCV: 4.7.0\n",
      "MMCV: 1.6.0\n",
      "MMCV Compiler: GCC 9.4\n",
      "MMCV CUDA Compiler: 11.8\n",
      "MMDetection: 2.25.0+c3bb258\n",
      "------------------------------------------------------------\n",
      "\n",
      "2023-05-23 14:17:17,088 - mmfewshot - INFO - Distributed training: False\n",
      "2023-05-23 14:17:17,662 - mmfewshot - INFO - Config:\n",
      "img_norm_cfg = dict(\n",
      "    mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n",
      "train_multi_pipelines = dict(\n",
      "    query=[\n",
      "        dict(type='LoadImageFromFile'),\n",
      "        dict(type='LoadAnnotations', with_bbox=True),\n",
      "        dict(\n",
      "            type='Resize',\n",
      "            img_scale=[(1000, 440), (1000, 472), (1000, 504), (1000, 536),\n",
      "                       (1000, 568), (1000, 600)],\n",
      "            keep_ratio=True,\n",
      "            multiscale_mode='value'),\n",
      "        dict(type='RandomFlip', flip_ratio=0.0),\n",
      "        dict(\n",
      "            type='Normalize',\n",
      "            mean=[103.53, 116.28, 123.675],\n",
      "            std=[1.0, 1.0, 1.0],\n",
      "            to_rgb=False),\n",
      "        dict(type='DefaultFormatBundle'),\n",
      "        dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "    ],\n",
      "    support=[\n",
      "        dict(type='LoadImageFromFile'),\n",
      "        dict(type='LoadAnnotations', with_bbox=True),\n",
      "        dict(\n",
      "            type='CropResizeInstance',\n",
      "            num_context_pixels=16,\n",
      "            target_size=(320, 320)),\n",
      "        dict(type='RandomFlip', flip_ratio=0.0),\n",
      "        dict(\n",
      "            type='Normalize',\n",
      "            mean=[103.53, 116.28, 123.675],\n",
      "            std=[1.0, 1.0, 1.0],\n",
      "            to_rgb=False),\n",
      "        dict(type='DefaultFormatBundle'),\n",
      "        dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "    ])\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1000, 600),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[103.53, 116.28, 123.675],\n",
      "                std=[1.0, 1.0, 1.0],\n",
      "                to_rgb=False),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data_root = 'data/VOCdevkit/'\n",
      "data = dict(\n",
      "    samples_per_gpu=1,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='QueryAwareDataset',\n",
      "        num_support_ways=2,\n",
      "        num_support_shots=4,\n",
      "        save_dataset=True,\n",
      "        dataset=dict(\n",
      "            type='FewShotVOCDefaultDataset',\n",
      "            ann_cfg=[dict(method='Attention_RPN', setting='SPLIT1_5SHOT')],\n",
      "            img_prefix='data/VOCdevkit/',\n",
      "            multi_pipelines=dict(\n",
      "                query=[\n",
      "                    dict(type='LoadImageFromFile'),\n",
      "                    dict(type='LoadAnnotations', with_bbox=True),\n",
      "                    dict(\n",
      "                        type='Resize',\n",
      "                        img_scale=[(1000, 440), (1000, 472), (1000, 504),\n",
      "                                   (1000, 536), (1000, 568), (1000, 600)],\n",
      "                        keep_ratio=True,\n",
      "                        multiscale_mode='value'),\n",
      "                    dict(type='RandomFlip', flip_ratio=0.0),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[103.53, 116.28, 123.675],\n",
      "                        std=[1.0, 1.0, 1.0],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='DefaultFormatBundle'),\n",
      "                    dict(\n",
      "                        type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "                ],\n",
      "                support=[\n",
      "                    dict(type='LoadImageFromFile'),\n",
      "                    dict(type='LoadAnnotations', with_bbox=True),\n",
      "                    dict(\n",
      "                        type='CropResizeInstance',\n",
      "                        num_context_pixels=16,\n",
      "                        target_size=(320, 320)),\n",
      "                    dict(type='RandomFlip', flip_ratio=0.0),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[103.53, 116.28, 123.675],\n",
      "                        std=[1.0, 1.0, 1.0],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='DefaultFormatBundle'),\n",
      "                    dict(\n",
      "                        type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "                ]),\n",
      "            classes='ALL_CLASSES_SPLIT1',\n",
      "            use_difficult=False,\n",
      "            instance_wise=False,\n",
      "            min_bbox_area=0,\n",
      "            dataset_name='query_support_dataset',\n",
      "            num_novel_shots=5,\n",
      "            num_base_shots=5)),\n",
      "    val=dict(\n",
      "        type='FewShotVOCDataset',\n",
      "        ann_cfg=[\n",
      "            dict(\n",
      "                type='ann_file',\n",
      "                ann_file='data/VOCdevkit/VOC2007/ImageSets/Main/test.txt')\n",
      "        ],\n",
      "        img_prefix='data/VOCdevkit/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1000, 600),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[103.53, 116.28, 123.675],\n",
      "                        std=[1.0, 1.0, 1.0],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        classes='ALL_CLASSES_SPLIT1'),\n",
      "    test=dict(\n",
      "        type='FewShotVOCDataset',\n",
      "        ann_cfg=[\n",
      "            dict(\n",
      "                type='ann_file',\n",
      "                ann_file='data/VOCdevkit/VOC2007/ImageSets/Main/test.txt')\n",
      "        ],\n",
      "        img_prefix='data/VOCdevkit/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1000, 600),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[103.53, 116.28, 123.675],\n",
      "                        std=[1.0, 1.0, 1.0],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        classes='ALL_CLASSES_SPLIT1'),\n",
      "    model_init=dict(\n",
      "        copy_from_train_dataset=True,\n",
      "        samples_per_gpu=16,\n",
      "        workers_per_gpu=1,\n",
      "        type='FewShotVOCDataset',\n",
      "        ann_cfg=None,\n",
      "        img_prefix='data/VOCdevkit/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                type='CropResizeInstance',\n",
      "                num_context_pixels=16,\n",
      "                target_size=(320, 320)),\n",
      "            dict(type='RandomFlip', flip_ratio=0.0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[103.53, 116.28, 123.675],\n",
      "                std=[1.0, 1.0, 1.0],\n",
      "                to_rgb=False),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ],\n",
      "        use_difficult=False,\n",
      "        instance_wise=True,\n",
      "        num_novel_shots=None,\n",
      "        classes='ALL_CLASSES_SPLIT1',\n",
      "        min_bbox_area=1024,\n",
      "        dataset_name='model_init_dataset'))\n",
      "evaluation = dict(\n",
      "    interval=400,\n",
      "    metric='mAP',\n",
      "    class_splits=['BASE_CLASSES_SPLIT1', 'NOVEL_CLASSES_SPLIT1'])\n",
      "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup=None,\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[1200])\n",
      "runner = dict(type='IterBasedRunner', max_iters=1200)\n",
      "norm_cfg = dict(type='BN', requires_grad=False)\n",
      "pretrained = 'open-mmlab://detectron2/resnet50_caffe'\n",
      "model = dict(\n",
      "    type='AttentionRPNDetector',\n",
      "    pretrained='open-mmlab://detectron2/resnet50_caffe',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=3,\n",
      "        strides=(1, 2, 2),\n",
      "        dilations=(1, 1, 1),\n",
      "        out_indices=(2, ),\n",
      "        frozen_stages=2,\n",
      "        norm_cfg=dict(type='BN', requires_grad=False),\n",
      "        norm_eval=True,\n",
      "        style='caffe'),\n",
      "    rpn_head=dict(\n",
      "        type='AttentionRPNHead',\n",
      "        in_channels=1024,\n",
      "        feat_channels=1024,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[2, 4, 8, 16, 32],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            scale_major=False,\n",
      "            strides=[16]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0),\n",
      "        num_support_ways=2,\n",
      "        num_support_shots=4,\n",
      "        roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
      "            out_channels=1024,\n",
      "            featmap_strides=[16]),\n",
      "        aggregation_layer=dict(\n",
      "            type='AggregationLayer',\n",
      "            aggregator_cfgs=[\n",
      "                dict(\n",
      "                    type='DepthWiseCorrelationAggregator',\n",
      "                    in_channels=1024,\n",
      "                    with_fc=False)\n",
      "            ])),\n",
      "    roi_head=dict(\n",
      "        type='MultiRelationRoIHead',\n",
      "        shared_head=dict(\n",
      "            type='ResLayer',\n",
      "            pretrained='open-mmlab://detectron2/resnet50_caffe',\n",
      "            depth=50,\n",
      "            stage=3,\n",
      "            stride=2,\n",
      "            dilation=1,\n",
      "            style='caffe',\n",
      "            norm_cfg=dict(type='BN', requires_grad=False),\n",
      "            norm_eval=True),\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
      "            out_channels=1024,\n",
      "            featmap_strides=[16]),\n",
      "        bbox_head=dict(\n",
      "            type='MultiRelationBBoxHead',\n",
      "            with_avg_pool=True,\n",
      "            roi_feat_size=14,\n",
      "            in_channels=2048,\n",
      "            num_classes=1,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=True,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0),\n",
      "            patch_relation=True,\n",
      "            local_correlation=True,\n",
      "            global_relation=True,\n",
      "            init_cfg=[\n",
      "                dict(\n",
      "                    type='Normal',\n",
      "                    override=dict(\n",
      "                        type='Normal', name='patch_relation_branch',\n",
      "                        std=0.01)),\n",
      "                dict(\n",
      "                    type='Normal',\n",
      "                    override=dict(\n",
      "                        type='Normal', name='patch_relation_fc_cls',\n",
      "                        std=0.01)),\n",
      "                dict(\n",
      "                    type='Normal',\n",
      "                    override=dict(\n",
      "                        type='Normal', name='patch_relation_fc_reg',\n",
      "                        std=0.001)),\n",
      "                dict(\n",
      "                    type='Normal',\n",
      "                    override=dict(\n",
      "                        type='Normal',\n",
      "                        name='local_correlation_branch',\n",
      "                        std=0.01)),\n",
      "                dict(\n",
      "                    type='Normal',\n",
      "                    override=dict(\n",
      "                        type='Normal',\n",
      "                        name='local_correlation_fc_cls',\n",
      "                        std=0.01)),\n",
      "                dict(\n",
      "                    type='Normal',\n",
      "                    override=dict(\n",
      "                        type='Normal', name='global_relation_branch',\n",
      "                        std=0.01)),\n",
      "                dict(\n",
      "                    type='Normal',\n",
      "                    override=dict(\n",
      "                        type='Normal', name='global_relation_fc_cls',\n",
      "                        std=0.01))\n",
      "            ]),\n",
      "        num_support_ways=2,\n",
      "        num_support_shots=4),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=-1,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=12000,\n",
      "            max_per_img=2000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=False,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=128,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            pos_weight=-1,\n",
      "            debug=False)),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=6000,\n",
      "            max_per_img=100,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100)),\n",
      "    frozen_parameters=[\n",
      "        'backbone', 'shared_head', 'rpn_head', 'aggregation_layer'\n",
      "    ])\n",
      "num_support_ways = 2\n",
      "num_support_shots = 4\n",
      "checkpoint_config = dict(interval=400)\n",
      "log_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = '/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/work_dirs/base_model/attention-rpn_r50_c4_voc-split1_base-training_20211101_003606-58a8f413.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "use_infinite_sampler = True\n",
      "seed = 42\n",
      "work_dir = 'work_dirs/additional_focus/3848'\n",
      "gpu_ids = [0]\n",
      "\n",
      "2023-05-23 14:17:17,662 - mmfewshot - INFO - Set random seed to 42, deterministic: False\n",
      "/home/tanluuuuuuu/miniconda3/envs/mmfewshot/lib/python3.8/site-packages/mmdet/models/backbones/resnet.py:401: UserWarning: DeprecationWarning: pretrained is deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is deprecated, '\n",
      "/home/tanluuuuuuu/miniconda3/envs/mmfewshot/lib/python3.8/site-packages/mmdet/models/roi_heads/shared_heads/res_layer.py:54: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
      "2023-05-23 14:17:17,885 - mmfewshot - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'open-mmlab://detectron2/resnet50_caffe'}\n",
      "2023-05-23 14:17:17,885 - mmcv - INFO - load model from: open-mmlab://detectron2/resnet50_caffe\n",
      "2023-05-23 14:17:17,885 - mmcv - INFO - load checkpoint from openmmlab path: open-mmlab://detectron2/resnet50_caffe\n",
      "2023-05-23 14:17:17,969 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: layer4.0.downsample.0.weight, layer4.0.downsample.1.bias, layer4.0.downsample.1.weight, layer4.0.downsample.1.running_mean, layer4.0.downsample.1.running_var, layer4.0.conv1.weight, layer4.0.bn1.bias, layer4.0.bn1.weight, layer4.0.bn1.running_mean, layer4.0.bn1.running_var, layer4.0.conv2.weight, layer4.0.bn2.bias, layer4.0.bn2.weight, layer4.0.bn2.running_mean, layer4.0.bn2.running_var, layer4.0.conv3.weight, layer4.0.bn3.bias, layer4.0.bn3.weight, layer4.0.bn3.running_mean, layer4.0.bn3.running_var, layer4.1.conv1.weight, layer4.1.bn1.bias, layer4.1.bn1.weight, layer4.1.bn1.running_mean, layer4.1.bn1.running_var, layer4.1.conv2.weight, layer4.1.bn2.bias, layer4.1.bn2.weight, layer4.1.bn2.running_mean, layer4.1.bn2.running_var, layer4.1.conv3.weight, layer4.1.bn3.bias, layer4.1.bn3.weight, layer4.1.bn3.running_mean, layer4.1.bn3.running_var, layer4.2.conv1.weight, layer4.2.bn1.bias, layer4.2.bn1.weight, layer4.2.bn1.running_mean, layer4.2.bn1.running_var, layer4.2.conv2.weight, layer4.2.bn2.bias, layer4.2.bn2.weight, layer4.2.bn2.running_mean, layer4.2.bn2.running_var, layer4.2.conv3.weight, layer4.2.bn3.bias, layer4.2.bn3.weight, layer4.2.bn3.running_mean, layer4.2.bn3.running_var, conv1.bias\n",
      "\n",
      "2023-05-23 14:17:17,975 - mmfewshot - INFO - initialize AttentionRPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
      "2023-05-23 14:17:18,003 - mmfewshot - INFO - initialize ResLayer with init_cfg {'type': 'Pretrained', 'checkpoint': 'open-mmlab://detectron2/resnet50_caffe'}\n",
      "2023-05-23 14:17:18,003 - mmcv - INFO - load model from: open-mmlab://detectron2/resnet50_caffe\n",
      "2023-05-23 14:17:18,003 - mmcv - INFO - load checkpoint from openmmlab path: open-mmlab://detectron2/resnet50_caffe\n",
      "2023-05-23 14:17:18,035 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: conv1.weight, conv1.bias, bn1.bias, bn1.weight, bn1.running_mean, bn1.running_var, layer1.0.downsample.0.weight, layer1.0.downsample.1.bias, layer1.0.downsample.1.weight, layer1.0.downsample.1.running_mean, layer1.0.downsample.1.running_var, layer1.0.conv1.weight, layer1.0.bn1.bias, layer1.0.bn1.weight, layer1.0.bn1.running_mean, layer1.0.bn1.running_var, layer1.0.conv2.weight, layer1.0.bn2.bias, layer1.0.bn2.weight, layer1.0.bn2.running_mean, layer1.0.bn2.running_var, layer1.0.conv3.weight, layer1.0.bn3.bias, layer1.0.bn3.weight, layer1.0.bn3.running_mean, layer1.0.bn3.running_var, layer1.1.conv1.weight, layer1.1.bn1.bias, layer1.1.bn1.weight, layer1.1.bn1.running_mean, layer1.1.bn1.running_var, layer1.1.conv2.weight, layer1.1.bn2.bias, layer1.1.bn2.weight, layer1.1.bn2.running_mean, layer1.1.bn2.running_var, layer1.1.conv3.weight, layer1.1.bn3.bias, layer1.1.bn3.weight, layer1.1.bn3.running_mean, layer1.1.bn3.running_var, layer1.2.conv1.weight, layer1.2.bn1.bias, layer1.2.bn1.weight, layer1.2.bn1.running_mean, layer1.2.bn1.running_var, layer1.2.conv2.weight, layer1.2.bn2.bias, layer1.2.bn2.weight, layer1.2.bn2.running_mean, layer1.2.bn2.running_var, layer1.2.conv3.weight, layer1.2.bn3.bias, layer1.2.bn3.weight, layer1.2.bn3.running_mean, layer1.2.bn3.running_var, layer2.0.downsample.0.weight, layer2.0.downsample.1.bias, layer2.0.downsample.1.weight, layer2.0.downsample.1.running_mean, layer2.0.downsample.1.running_var, layer2.0.conv1.weight, layer2.0.bn1.bias, layer2.0.bn1.weight, layer2.0.bn1.running_mean, layer2.0.bn1.running_var, layer2.0.conv2.weight, layer2.0.bn2.bias, layer2.0.bn2.weight, layer2.0.bn2.running_mean, layer2.0.bn2.running_var, layer2.0.conv3.weight, layer2.0.bn3.bias, layer2.0.bn3.weight, layer2.0.bn3.running_mean, layer2.0.bn3.running_var, layer2.1.conv1.weight, layer2.1.bn1.bias, layer2.1.bn1.weight, layer2.1.bn1.running_mean, layer2.1.bn1.running_var, layer2.1.conv2.weight, layer2.1.bn2.bias, layer2.1.bn2.weight, layer2.1.bn2.running_mean, layer2.1.bn2.running_var, layer2.1.conv3.weight, layer2.1.bn3.bias, layer2.1.bn3.weight, layer2.1.bn3.running_mean, layer2.1.bn3.running_var, layer2.2.conv1.weight, layer2.2.bn1.bias, layer2.2.bn1.weight, layer2.2.bn1.running_mean, layer2.2.bn1.running_var, layer2.2.conv2.weight, layer2.2.bn2.bias, layer2.2.bn2.weight, layer2.2.bn2.running_mean, layer2.2.bn2.running_var, layer2.2.conv3.weight, layer2.2.bn3.bias, layer2.2.bn3.weight, layer2.2.bn3.running_mean, layer2.2.bn3.running_var, layer2.3.conv1.weight, layer2.3.bn1.bias, layer2.3.bn1.weight, layer2.3.bn1.running_mean, layer2.3.bn1.running_var, layer2.3.conv2.weight, layer2.3.bn2.bias, layer2.3.bn2.weight, layer2.3.bn2.running_mean, layer2.3.bn2.running_var, layer2.3.conv3.weight, layer2.3.bn3.bias, layer2.3.bn3.weight, layer2.3.bn3.running_mean, layer2.3.bn3.running_var, layer3.0.downsample.0.weight, layer3.0.downsample.1.bias, layer3.0.downsample.1.weight, layer3.0.downsample.1.running_mean, layer3.0.downsample.1.running_var, layer3.0.conv1.weight, layer3.0.bn1.bias, layer3.0.bn1.weight, layer3.0.bn1.running_mean, layer3.0.bn1.running_var, layer3.0.conv2.weight, layer3.0.bn2.bias, layer3.0.bn2.weight, layer3.0.bn2.running_mean, layer3.0.bn2.running_var, layer3.0.conv3.weight, layer3.0.bn3.bias, layer3.0.bn3.weight, layer3.0.bn3.running_mean, layer3.0.bn3.running_var, layer3.1.conv1.weight, layer3.1.bn1.bias, layer3.1.bn1.weight, layer3.1.bn1.running_mean, layer3.1.bn1.running_var, layer3.1.conv2.weight, layer3.1.bn2.bias, layer3.1.bn2.weight, layer3.1.bn2.running_mean, layer3.1.bn2.running_var, layer3.1.conv3.weight, layer3.1.bn3.bias, layer3.1.bn3.weight, layer3.1.bn3.running_mean, layer3.1.bn3.running_var, layer3.2.conv1.weight, layer3.2.bn1.bias, layer3.2.bn1.weight, layer3.2.bn1.running_mean, layer3.2.bn1.running_var, layer3.2.conv2.weight, layer3.2.bn2.bias, layer3.2.bn2.weight, layer3.2.bn2.running_mean, layer3.2.bn2.running_var, layer3.2.conv3.weight, layer3.2.bn3.bias, layer3.2.bn3.weight, layer3.2.bn3.running_mean, layer3.2.bn3.running_var, layer3.3.conv1.weight, layer3.3.bn1.bias, layer3.3.bn1.weight, layer3.3.bn1.running_mean, layer3.3.bn1.running_var, layer3.3.conv2.weight, layer3.3.bn2.bias, layer3.3.bn2.weight, layer3.3.bn2.running_mean, layer3.3.bn2.running_var, layer3.3.conv3.weight, layer3.3.bn3.bias, layer3.3.bn3.weight, layer3.3.bn3.running_mean, layer3.3.bn3.running_var, layer3.4.conv1.weight, layer3.4.bn1.bias, layer3.4.bn1.weight, layer3.4.bn1.running_mean, layer3.4.bn1.running_var, layer3.4.conv2.weight, layer3.4.bn2.bias, layer3.4.bn2.weight, layer3.4.bn2.running_mean, layer3.4.bn2.running_var, layer3.4.conv3.weight, layer3.4.bn3.bias, layer3.4.bn3.weight, layer3.4.bn3.running_mean, layer3.4.bn3.running_var, layer3.5.conv1.weight, layer3.5.bn1.bias, layer3.5.bn1.weight, layer3.5.bn1.running_mean, layer3.5.bn1.running_var, layer3.5.conv2.weight, layer3.5.bn2.bias, layer3.5.bn2.weight, layer3.5.bn2.running_mean, layer3.5.bn2.running_var, layer3.5.conv3.weight, layer3.5.bn3.bias, layer3.5.bn3.weight, layer3.5.bn3.running_mean, layer3.5.bn3.running_var\n",
      "\n",
      "2023-05-23 14:17:18,040 - mmfewshot - INFO - initialize MultiRelationBBoxHead with init_cfg [{'type': 'Normal', 'override': {'type': 'Normal', 'name': 'patch_relation_branch', 'std': 0.01}}, {'type': 'Normal', 'override': {'type': 'Normal', 'name': 'patch_relation_fc_cls', 'std': 0.01}}, {'type': 'Normal', 'override': {'type': 'Normal', 'name': 'patch_relation_fc_reg', 'std': 0.001}}, {'type': 'Normal', 'override': {'type': 'Normal', 'name': 'local_correlation_branch', 'std': 0.01}}, {'type': 'Normal', 'override': {'type': 'Normal', 'name': 'local_correlation_fc_cls', 'std': 0.01}}, {'type': 'Normal', 'override': {'type': 'Normal', 'name': 'global_relation_branch', 'std': 0.01}}, {'type': 'Normal', 'override': {'type': 'Normal', 'name': 'global_relation_fc_cls', 'std': 0.01}}]\n",
      "2023-05-23 14:17:18,127 - mmfewshot - INFO - Frozen parameters: ['backbone', 'shared_head', 'rpn_head', 'aggregation_layer']\n",
      "2023-05-23 14:17:18,127 - mmfewshot - INFO - Training parameters: roi_head.bbox_head.patch_relation_branch.0.weight\n",
      "2023-05-23 14:17:18,127 - mmfewshot - INFO - Training parameters: roi_head.bbox_head.patch_relation_branch.3.weight\n",
      "2023-05-23 14:17:18,127 - mmfewshot - INFO - Training parameters: roi_head.bbox_head.patch_relation_branch.5.weight\n",
      "2023-05-23 14:17:18,128 - mmfewshot - INFO - Training parameters: roi_head.bbox_head.patch_relation_fc_reg.weight\n",
      "2023-05-23 14:17:18,128 - mmfewshot - INFO - Training parameters: roi_head.bbox_head.patch_relation_fc_reg.bias\n",
      "2023-05-23 14:17:18,128 - mmfewshot - INFO - Training parameters: roi_head.bbox_head.patch_relation_fc_cls.weight\n",
      "2023-05-23 14:17:18,128 - mmfewshot - INFO - Training parameters: roi_head.bbox_head.patch_relation_fc_cls.bias\n",
      "2023-05-23 14:17:18,128 - mmfewshot - INFO - Training parameters: roi_head.bbox_head.local_correlation_branch.0.weight\n",
      "2023-05-23 14:17:18,128 - mmfewshot - INFO - Training parameters: roi_head.bbox_head.local_correlation_fc_cls.weight\n",
      "2023-05-23 14:17:18,128 - mmfewshot - INFO - Training parameters: roi_head.bbox_head.local_correlation_fc_cls.bias\n",
      "2023-05-23 14:17:18,128 - mmfewshot - INFO - Training parameters: roi_head.bbox_head.global_relation_branch.0.weight\n",
      "2023-05-23 14:17:18,128 - mmfewshot - INFO - Training parameters: roi_head.bbox_head.global_relation_branch.0.bias\n",
      "2023-05-23 14:17:18,128 - mmfewshot - INFO - Training parameters: roi_head.bbox_head.global_relation_branch.2.weight\n",
      "2023-05-23 14:17:18,128 - mmfewshot - INFO - Training parameters: roi_head.bbox_head.global_relation_branch.2.bias\n",
      "2023-05-23 14:17:18,128 - mmfewshot - INFO - Training parameters: roi_head.bbox_head.global_relation_fc_cls.weight\n",
      "2023-05-23 14:17:18,128 - mmfewshot - INFO - Training parameters: roi_head.bbox_head.global_relation_fc_cls.bias\n",
      "2023-05-23 14:17:18,145 - mmfewshot - INFO - \n",
      "FewShotVOCDefaultDataset query_support_dataset with number of images 58, and instance counts: \n",
      "+---------------+-------+------------------+-------+-----------------+-------+------------+-------+----------------+-------+\n",
      "| category      | count | category         | count | category        | count | category   | count | category       | count |\n",
      "+---------------+-------+------------------+-------+-----------------+-------+------------+-------+----------------+-------+\n",
      "| 0 [aeroplane] | 5     | 1 [bicycle]      | 5     | 2 [boat]        | 5     | 3 [bottle] | 5     | 4 [car]        | 5     |\n",
      "| 5 [cat]       | 5     | 6 [chair]        | 5     | 7 [diningtable] | 5     | 8 [dog]    | 5     | 9 [horse]      | 5     |\n",
      "| 10 [person]   | 5     | 11 [pottedplant] | 5     | 12 [sheep]      | 5     | 13 [train] | 5     | 14 [tvmonitor] | 5     |\n",
      "| 15 [3848]     | 5     | -1 background    | 0     |                 |       |            |       |                |       |\n",
      "+---------------+-------+------------------+-------+-----------------+-------+------------+-------+----------------+-------+\n",
      "2023-05-23 14:17:19,383 - mmfewshot - INFO - load checkpoint from local path: /home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/work_dirs/base_model/attention-rpn_r50_c4_voc-split1_base-training_20211101_003606-58a8f413.pth\n",
      "2023-05-23 14:17:19,623 - mmfewshot - INFO - Start running, host: tanluuuuuuu@tanluuuuuuu, work_dir: /home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/work_dirs/additional_focus/3848\n",
      "2023-05-23 14:17:19,623 - mmfewshot - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2023-05-23 14:17:19,623 - mmfewshot - INFO - workflow: [('train', 1)], max: 1200 iters\n",
      "2023-05-23 14:17:19,623 - mmfewshot - INFO - Checkpoints will be saved to /home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/work_dirs/additional_focus/3848 by HardDiskBackend.\n",
      "/home/tanluuuuuuu/miniconda3/envs/mmfewshot/lib/python3.8/site-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\n",
      "2023-05-23 14:17:23,806 - mmfewshot - INFO - Iter [10/1200]\tlr: 1.000e-03, eta: 0:08:07, time: 0.410, data_time: 0.019, memory: 1044, loss_rpn_cls: 0.0628, loss_rpn_bbox: 0.0295, loss_cls: 0.1944, acc: 98.4766, loss_bbox: 0.1446, loss: 0.4313\n",
      "2023-05-23 14:17:25,763 - mmfewshot - INFO - Iter [20/1200]\tlr: 1.000e-03, eta: 0:05:57, time: 0.196, data_time: 0.009, memory: 1045, loss_rpn_cls: 0.0773, loss_rpn_bbox: 0.0236, loss_cls: 0.0902, acc: 98.7109, loss_bbox: 0.0888, loss: 0.2799\n",
      "2023-05-23 14:17:27,722 - mmfewshot - INFO - Iter [30/1200]\tlr: 1.000e-03, eta: 0:05:12, time: 0.196, data_time: 0.009, memory: 1045, loss_rpn_cls: 0.1529, loss_rpn_bbox: 0.0228, loss_cls: 0.3932, acc: 97.2266, loss_bbox: 0.1224, loss: 0.6914\n",
      "2023-05-23 14:17:29,671 - mmfewshot - INFO - Iter [40/1200]\tlr: 1.000e-03, eta: 0:04:48, time: 0.195, data_time: 0.009, memory: 1045, loss_rpn_cls: 0.0760, loss_rpn_bbox: 0.0308, loss_cls: 0.0737, acc: 98.0469, loss_bbox: 0.1819, loss: 0.3624\n",
      "2023-05-23 14:17:31,580 - mmfewshot - INFO - Iter [50/1200]\tlr: 1.000e-03, eta: 0:04:33, time: 0.191, data_time: 0.009, memory: 1045, loss_rpn_cls: 0.0757, loss_rpn_bbox: 0.0143, loss_cls: 0.2113, acc: 97.5781, loss_bbox: 0.1657, loss: 0.4671\n",
      "2023-05-23 14:17:33,531 - mmfewshot - INFO - Iter [60/1200]\tlr: 1.000e-03, eta: 0:04:22, time: 0.195, data_time: 0.009, memory: 1048, loss_rpn_cls: 0.0476, loss_rpn_bbox: 0.0228, loss_cls: 0.0783, acc: 99.1797, loss_bbox: 0.1158, loss: 0.2644\n",
      "2023-05-23 14:17:35,476 - mmfewshot - INFO - Iter [70/1200]\tlr: 1.000e-03, eta: 0:04:14, time: 0.195, data_time: 0.009, memory: 1048, loss_rpn_cls: 0.2166, loss_rpn_bbox: 0.0370, loss_cls: 0.2371, acc: 98.8672, loss_bbox: 0.1346, loss: 0.6254\n",
      "2023-05-23 14:17:37,392 - mmfewshot - INFO - Iter [80/1200]\tlr: 1.000e-03, eta: 0:04:07, time: 0.192, data_time: 0.009, memory: 1048, loss_rpn_cls: 0.0747, loss_rpn_bbox: 0.0283, loss_cls: 0.1448, acc: 98.5938, loss_bbox: 0.1606, loss: 0.4085\n",
      "2023-05-23 14:17:39,321 - mmfewshot - INFO - Iter [90/1200]\tlr: 1.000e-03, eta: 0:04:01, time: 0.193, data_time: 0.009, memory: 1048, loss_rpn_cls: 0.0288, loss_rpn_bbox: 0.0063, loss_cls: 0.1456, acc: 97.5391, loss_bbox: 0.0962, loss: 0.2770\n",
      "2023-05-23 14:17:41,256 - mmfewshot - INFO - Iter [100/1200]\tlr: 1.000e-03, eta: 0:03:57, time: 0.193, data_time: 0.009, memory: 1048, loss_rpn_cls: 0.0895, loss_rpn_bbox: 0.0218, loss_cls: 0.1075, acc: 98.5938, loss_bbox: 0.1406, loss: 0.3594\n",
      "2023-05-23 14:17:43,185 - mmfewshot - INFO - Iter [110/1200]\tlr: 1.000e-03, eta: 0:03:52, time: 0.193, data_time: 0.009, memory: 1048, loss_rpn_cls: 0.0758, loss_rpn_bbox: 0.0207, loss_cls: 0.1290, acc: 98.4375, loss_bbox: 0.1254, loss: 0.3509\n",
      "2023-05-23 14:17:45,171 - mmfewshot - INFO - Iter [120/1200]\tlr: 1.000e-03, eta: 0:03:49, time: 0.197, data_time: 0.009, memory: 1048, loss_rpn_cls: 0.0711, loss_rpn_bbox: 0.0179, loss_cls: 0.1650, acc: 98.2031, loss_bbox: 0.1296, loss: 0.3835\n",
      "2023-05-23 14:17:47,145 - mmfewshot - INFO - Iter [130/1200]\tlr: 1.000e-03, eta: 0:03:45, time: 0.198, data_time: 0.010, memory: 1048, loss_rpn_cls: 0.0894, loss_rpn_bbox: 0.0190, loss_cls: 0.1033, acc: 98.3984, loss_bbox: 0.1345, loss: 0.3461\n",
      "2023-05-23 14:17:49,092 - mmfewshot - INFO - Iter [140/1200]\tlr: 1.000e-03, eta: 0:03:42, time: 0.195, data_time: 0.009, memory: 1048, loss_rpn_cls: 0.0684, loss_rpn_bbox: 0.0300, loss_cls: 0.0900, acc: 98.8672, loss_bbox: 0.1770, loss: 0.3654\n",
      "2023-05-23 14:17:51,025 - mmfewshot - INFO - Iter [150/1200]\tlr: 1.000e-03, eta: 0:03:39, time: 0.193, data_time: 0.009, memory: 1048, loss_rpn_cls: 0.0915, loss_rpn_bbox: 0.0271, loss_cls: 0.1064, acc: 98.7500, loss_bbox: 0.1150, loss: 0.3400\n",
      "2023-05-23 14:17:52,992 - mmfewshot - INFO - Iter [160/1200]\tlr: 1.000e-03, eta: 0:03:36, time: 0.197, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0477, loss_rpn_bbox: 0.0193, loss_cls: 0.0809, acc: 98.9844, loss_bbox: 0.0923, loss: 0.2402\n",
      "2023-05-23 14:17:54,969 - mmfewshot - INFO - Iter [170/1200]\tlr: 1.000e-03, eta: 0:03:33, time: 0.198, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0911, loss_rpn_bbox: 0.0206, loss_cls: 0.0600, acc: 99.0625, loss_bbox: 0.1158, loss: 0.2875\n",
      "2023-05-23 14:17:56,924 - mmfewshot - INFO - Iter [180/1200]\tlr: 1.000e-03, eta: 0:03:30, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0681, loss_rpn_bbox: 0.0237, loss_cls: 0.0635, acc: 99.2188, loss_bbox: 0.1250, loss: 0.2803\n",
      "2023-05-23 14:17:58,867 - mmfewshot - INFO - Iter [190/1200]\tlr: 1.000e-03, eta: 0:03:28, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0442, loss_rpn_bbox: 0.0113, loss_cls: 0.1002, acc: 99.0234, loss_bbox: 0.1292, loss: 0.2850\n",
      "2023-05-23 14:18:00,835 - mmfewshot - INFO - Iter [200/1200]\tlr: 1.000e-03, eta: 0:03:25, time: 0.197, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0251, loss_rpn_bbox: 0.0217, loss_cls: 0.0372, acc: 99.5703, loss_bbox: 0.0656, loss: 0.1497\n",
      "2023-05-23 14:18:02,777 - mmfewshot - INFO - Iter [210/1200]\tlr: 1.000e-03, eta: 0:03:23, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0393, loss_rpn_bbox: 0.0244, loss_cls: 0.0899, acc: 99.0234, loss_bbox: 0.1324, loss: 0.2860\n",
      "2023-05-23 14:18:04,717 - mmfewshot - INFO - Iter [220/1200]\tlr: 1.000e-03, eta: 0:03:20, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.2307, loss_rpn_bbox: 0.0337, loss_cls: 0.0838, acc: 99.1406, loss_bbox: 0.1710, loss: 0.5192\n",
      "2023-05-23 14:18:06,672 - mmfewshot - INFO - Iter [230/1200]\tlr: 1.000e-03, eta: 0:03:18, time: 0.196, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0442, loss_rpn_bbox: 0.0410, loss_cls: 0.0598, acc: 99.1016, loss_bbox: 0.0874, loss: 0.2323\n",
      "2023-05-23 14:18:08,624 - mmfewshot - INFO - Iter [240/1200]\tlr: 1.000e-03, eta: 0:03:15, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0594, loss_rpn_bbox: 0.0243, loss_cls: 0.1570, acc: 99.4141, loss_bbox: 0.1139, loss: 0.3545\n",
      "2023-05-23 14:18:10,610 - mmfewshot - INFO - Iter [250/1200]\tlr: 1.000e-03, eta: 0:03:13, time: 0.199, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.1610, loss_rpn_bbox: 0.0359, loss_cls: 0.0980, acc: 98.8672, loss_bbox: 0.1304, loss: 0.4253\n",
      "2023-05-23 14:18:12,570 - mmfewshot - INFO - Iter [260/1200]\tlr: 1.000e-03, eta: 0:03:11, time: 0.196, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.0309, loss_rpn_bbox: 0.0411, loss_cls: 0.0552, acc: 99.4922, loss_bbox: 0.0941, loss: 0.2212\n",
      "2023-05-23 14:18:14,513 - mmfewshot - INFO - Iter [270/1200]\tlr: 1.000e-03, eta: 0:03:08, time: 0.194, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.1239, loss_rpn_bbox: 0.0248, loss_cls: 0.0662, acc: 99.1406, loss_bbox: 0.1668, loss: 0.3817\n",
      "2023-05-23 14:18:16,474 - mmfewshot - INFO - Iter [280/1200]\tlr: 1.000e-03, eta: 0:03:06, time: 0.196, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0245, loss_rpn_bbox: 0.0158, loss_cls: 0.0378, acc: 99.3750, loss_bbox: 0.1235, loss: 0.2015\n",
      "2023-05-23 14:18:18,422 - mmfewshot - INFO - Iter [290/1200]\tlr: 1.000e-03, eta: 0:03:04, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0685, loss_rpn_bbox: 0.0163, loss_cls: 0.0627, acc: 99.2969, loss_bbox: 0.1243, loss: 0.2718\n",
      "2023-05-23 14:18:20,377 - mmfewshot - INFO - Iter [300/1200]\tlr: 1.000e-03, eta: 0:03:02, time: 0.195, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.0323, loss_rpn_bbox: 0.0133, loss_cls: 0.0455, acc: 99.5312, loss_bbox: 0.0806, loss: 0.1717\n",
      "2023-05-23 14:18:22,334 - mmfewshot - INFO - Iter [310/1200]\tlr: 1.000e-03, eta: 0:02:59, time: 0.196, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0881, loss_rpn_bbox: 0.0167, loss_cls: 0.0662, acc: 99.1016, loss_bbox: 0.1510, loss: 0.3220\n",
      "2023-05-23 14:18:24,284 - mmfewshot - INFO - Iter [320/1200]\tlr: 1.000e-03, eta: 0:02:57, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0835, loss_rpn_bbox: 0.0156, loss_cls: 0.0622, acc: 99.2969, loss_bbox: 0.1117, loss: 0.2730\n",
      "2023-05-23 14:18:26,282 - mmfewshot - INFO - Iter [330/1200]\tlr: 1.000e-03, eta: 0:02:55, time: 0.199, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.1648, loss_rpn_bbox: 0.0449, loss_cls: 0.1062, acc: 99.2188, loss_bbox: 0.1060, loss: 0.4220\n",
      "2023-05-23 14:18:28,262 - mmfewshot - INFO - Iter [340/1200]\tlr: 1.000e-03, eta: 0:02:53, time: 0.198, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.0614, loss_rpn_bbox: 0.0366, loss_cls: 0.0526, acc: 99.4141, loss_bbox: 0.1430, loss: 0.2936\n",
      "2023-05-23 14:18:30,230 - mmfewshot - INFO - Iter [350/1200]\tlr: 1.000e-03, eta: 0:02:51, time: 0.197, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.0313, loss_rpn_bbox: 0.0162, loss_cls: 0.0429, acc: 99.2969, loss_bbox: 0.1243, loss: 0.2146\n",
      "2023-05-23 14:18:32,198 - mmfewshot - INFO - Iter [360/1200]\tlr: 1.000e-03, eta: 0:02:49, time: 0.197, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.2067, loss_rpn_bbox: 0.0359, loss_cls: 0.0606, acc: 99.1406, loss_bbox: 0.1072, loss: 0.4105\n",
      "2023-05-23 14:18:34,149 - mmfewshot - INFO - Iter [370/1200]\tlr: 1.000e-03, eta: 0:02:46, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0602, loss_rpn_bbox: 0.0198, loss_cls: 0.0474, acc: 99.4922, loss_bbox: 0.0719, loss: 0.1993\n",
      "2023-05-23 14:18:36,091 - mmfewshot - INFO - Iter [380/1200]\tlr: 1.000e-03, eta: 0:02:44, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.2293, loss_rpn_bbox: 0.0266, loss_cls: 0.0559, acc: 99.3359, loss_bbox: 0.1324, loss: 0.4442\n",
      "2023-05-23 14:18:38,061 - mmfewshot - INFO - Iter [390/1200]\tlr: 1.000e-03, eta: 0:02:42, time: 0.197, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0478, loss_rpn_bbox: 0.0242, loss_cls: 0.0490, acc: 99.2969, loss_bbox: 0.0943, loss: 0.2153\n",
      "2023-05-23 14:18:39,974 - mmfewshot - INFO - Saving checkpoint at 400 iterations\n",
      "2023-05-23 14:18:40,559 - mmfewshot - INFO - Iter [400/1200]\tlr: 1.000e-03, eta: 0:02:41, time: 0.255, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0745, loss_rpn_bbox: 0.0217, loss_cls: 0.0487, acc: 99.4531, loss_bbox: 0.1302, loss: 0.2751\n",
      "2023-05-23 14:18:42,547 - mmfewshot - INFO - Iter [410/1200]\tlr: 1.000e-03, eta: 0:02:39, time: 0.194, data_time: 0.004, memory: 1049, loss_rpn_cls: 0.0560, loss_rpn_bbox: 0.0318, loss_cls: 0.0918, acc: 98.9453, loss_bbox: 0.1428, loss: 0.3224\n",
      "2023-05-23 14:18:44,509 - mmfewshot - INFO - Iter [420/1200]\tlr: 1.000e-03, eta: 0:02:37, time: 0.196, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.0462, loss_rpn_bbox: 0.0277, loss_cls: 0.0622, acc: 99.4141, loss_bbox: 0.1379, loss: 0.2739\n",
      "2023-05-23 14:18:46,487 - mmfewshot - INFO - Iter [430/1200]\tlr: 1.000e-03, eta: 0:02:35, time: 0.198, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.0667, loss_rpn_bbox: 0.0213, loss_cls: 0.0527, acc: 99.2578, loss_bbox: 0.1197, loss: 0.2604\n",
      "2023-05-23 14:18:48,422 - mmfewshot - INFO - Iter [440/1200]\tlr: 1.000e-03, eta: 0:02:33, time: 0.193, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.1101, loss_rpn_bbox: 0.0161, loss_cls: 0.0591, acc: 99.4922, loss_bbox: 0.1090, loss: 0.2944\n",
      "2023-05-23 14:18:50,382 - mmfewshot - INFO - Iter [450/1200]\tlr: 1.000e-03, eta: 0:02:31, time: 0.196, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0339, loss_rpn_bbox: 0.0187, loss_cls: 0.0519, acc: 99.2969, loss_bbox: 0.1015, loss: 0.2060\n",
      "2023-05-23 14:18:52,340 - mmfewshot - INFO - Iter [460/1200]\tlr: 1.000e-03, eta: 0:02:29, time: 0.196, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0442, loss_rpn_bbox: 0.0216, loss_cls: 0.0571, acc: 98.8672, loss_bbox: 0.1150, loss: 0.2379\n",
      "2023-05-23 14:18:54,300 - mmfewshot - INFO - Iter [470/1200]\tlr: 1.000e-03, eta: 0:02:26, time: 0.196, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0248, loss_rpn_bbox: 0.0277, loss_cls: 0.0395, acc: 99.3750, loss_bbox: 0.1129, loss: 0.2049\n",
      "2023-05-23 14:18:56,265 - mmfewshot - INFO - Iter [480/1200]\tlr: 1.000e-03, eta: 0:02:24, time: 0.197, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0301, loss_rpn_bbox: 0.0123, loss_cls: 0.0534, acc: 98.9844, loss_bbox: 0.1457, loss: 0.2415\n",
      "2023-05-23 14:18:58,229 - mmfewshot - INFO - Iter [490/1200]\tlr: 1.000e-03, eta: 0:02:22, time: 0.196, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.2621, loss_rpn_bbox: 0.0317, loss_cls: 0.1739, acc: 99.2969, loss_bbox: 0.1302, loss: 0.5978\n",
      "2023-05-23 14:19:00,185 - mmfewshot - INFO - Iter [500/1200]\tlr: 1.000e-03, eta: 0:02:20, time: 0.196, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0387, loss_rpn_bbox: 0.0201, loss_cls: 0.0533, acc: 99.2578, loss_bbox: 0.1231, loss: 0.2351\n",
      "2023-05-23 14:19:02,143 - mmfewshot - INFO - Iter [510/1200]\tlr: 1.000e-03, eta: 0:02:18, time: 0.196, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.0183, loss_rpn_bbox: 0.0198, loss_cls: 0.0782, acc: 98.9844, loss_bbox: 0.0765, loss: 0.1928\n",
      "2023-05-23 14:19:04,087 - mmfewshot - INFO - Iter [520/1200]\tlr: 1.000e-03, eta: 0:02:16, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0834, loss_rpn_bbox: 0.0199, loss_cls: 0.0331, acc: 99.6484, loss_bbox: 0.1240, loss: 0.2604\n",
      "2023-05-23 14:19:06,036 - mmfewshot - INFO - Iter [530/1200]\tlr: 1.000e-03, eta: 0:02:14, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0590, loss_rpn_bbox: 0.0147, loss_cls: 0.3574, acc: 99.3359, loss_bbox: 0.0866, loss: 0.5178\n",
      "2023-05-23 14:19:08,015 - mmfewshot - INFO - Iter [540/1200]\tlr: 1.000e-03, eta: 0:02:12, time: 0.198, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0606, loss_rpn_bbox: 0.0257, loss_cls: 0.0890, acc: 99.1797, loss_bbox: 0.1396, loss: 0.3149\n",
      "2023-05-23 14:19:09,959 - mmfewshot - INFO - Iter [550/1200]\tlr: 1.000e-03, eta: 0:02:10, time: 0.194, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.1064, loss_rpn_bbox: 0.0184, loss_cls: 0.0474, acc: 99.4922, loss_bbox: 0.1204, loss: 0.2926\n",
      "2023-05-23 14:19:11,915 - mmfewshot - INFO - Iter [560/1200]\tlr: 1.000e-03, eta: 0:02:08, time: 0.196, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.0441, loss_rpn_bbox: 0.0195, loss_cls: 0.0268, acc: 99.7656, loss_bbox: 0.0935, loss: 0.1839\n",
      "2023-05-23 14:19:13,882 - mmfewshot - INFO - Iter [570/1200]\tlr: 1.000e-03, eta: 0:02:06, time: 0.197, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0752, loss_rpn_bbox: 0.0204, loss_cls: 0.0496, acc: 99.4141, loss_bbox: 0.0910, loss: 0.2361\n",
      "2023-05-23 14:19:15,842 - mmfewshot - INFO - Iter [580/1200]\tlr: 1.000e-03, eta: 0:02:04, time: 0.196, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.0419, loss_rpn_bbox: 0.0242, loss_cls: 0.0459, acc: 99.3359, loss_bbox: 0.1029, loss: 0.2149\n",
      "2023-05-23 14:19:17,787 - mmfewshot - INFO - Iter [590/1200]\tlr: 1.000e-03, eta: 0:02:02, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0588, loss_rpn_bbox: 0.0164, loss_cls: 0.0542, acc: 99.2578, loss_bbox: 0.1000, loss: 0.2294\n",
      "2023-05-23 14:19:19,736 - mmfewshot - INFO - Iter [600/1200]\tlr: 1.000e-03, eta: 0:02:00, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.1656, loss_rpn_bbox: 0.0257, loss_cls: 0.0349, acc: 99.7656, loss_bbox: 0.1059, loss: 0.3321\n",
      "2023-05-23 14:19:21,683 - mmfewshot - INFO - Iter [610/1200]\tlr: 1.000e-03, eta: 0:01:57, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0481, loss_rpn_bbox: 0.0191, loss_cls: 0.0448, acc: 99.6094, loss_bbox: 0.0715, loss: 0.1835\n",
      "2023-05-23 14:19:23,624 - mmfewshot - INFO - Iter [620/1200]\tlr: 1.000e-03, eta: 0:01:55, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0331, loss_rpn_bbox: 0.0232, loss_cls: 0.1168, acc: 97.8125, loss_bbox: 0.1280, loss: 0.3011\n",
      "2023-05-23 14:19:25,562 - mmfewshot - INFO - Iter [630/1200]\tlr: 1.000e-03, eta: 0:01:53, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0588, loss_rpn_bbox: 0.0330, loss_cls: 0.0787, acc: 99.0234, loss_bbox: 0.1441, loss: 0.3145\n",
      "2023-05-23 14:19:27,517 - mmfewshot - INFO - Iter [640/1200]\tlr: 1.000e-03, eta: 0:01:51, time: 0.195, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.0223, loss_rpn_bbox: 0.0214, loss_cls: 0.0599, acc: 99.2188, loss_bbox: 0.1191, loss: 0.2227\n",
      "2023-05-23 14:19:29,470 - mmfewshot - INFO - Iter [650/1200]\tlr: 1.000e-03, eta: 0:01:49, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.2087, loss_rpn_bbox: 0.0356, loss_cls: 0.0552, acc: 99.4922, loss_bbox: 0.0982, loss: 0.3978\n",
      "2023-05-23 14:19:31,426 - mmfewshot - INFO - Iter [660/1200]\tlr: 1.000e-03, eta: 0:01:47, time: 0.196, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0621, loss_rpn_bbox: 0.0185, loss_cls: 0.0471, acc: 99.6094, loss_bbox: 0.1361, loss: 0.2638\n",
      "2023-05-23 14:19:33,386 - mmfewshot - INFO - Iter [670/1200]\tlr: 1.000e-03, eta: 0:01:45, time: 0.196, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0269, loss_rpn_bbox: 0.0236, loss_cls: 0.0327, acc: 99.5312, loss_bbox: 0.0904, loss: 0.1735\n",
      "2023-05-23 14:19:35,333 - mmfewshot - INFO - Iter [680/1200]\tlr: 1.000e-03, eta: 0:01:43, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.1098, loss_rpn_bbox: 0.0233, loss_cls: 0.0642, acc: 99.2578, loss_bbox: 0.1206, loss: 0.3179\n",
      "2023-05-23 14:19:37,278 - mmfewshot - INFO - Iter [690/1200]\tlr: 1.000e-03, eta: 0:01:41, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0718, loss_rpn_bbox: 0.0178, loss_cls: 0.0573, acc: 99.6094, loss_bbox: 0.0638, loss: 0.2108\n",
      "2023-05-23 14:19:39,221 - mmfewshot - INFO - Iter [700/1200]\tlr: 1.000e-03, eta: 0:01:39, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0471, loss_rpn_bbox: 0.0227, loss_cls: 0.0525, acc: 99.2188, loss_bbox: 0.1297, loss: 0.2520\n",
      "2023-05-23 14:19:41,169 - mmfewshot - INFO - Iter [710/1200]\tlr: 1.000e-03, eta: 0:01:37, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.1752, loss_rpn_bbox: 0.0376, loss_cls: 0.0473, acc: 99.1016, loss_bbox: 0.1225, loss: 0.3826\n",
      "2023-05-23 14:19:43,123 - mmfewshot - INFO - Iter [720/1200]\tlr: 1.000e-03, eta: 0:01:35, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.1805, loss_rpn_bbox: 0.0356, loss_cls: 0.0451, acc: 99.4531, loss_bbox: 0.1344, loss: 0.3956\n",
      "2023-05-23 14:19:45,070 - mmfewshot - INFO - Iter [730/1200]\tlr: 1.000e-03, eta: 0:01:33, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.1097, loss_rpn_bbox: 0.0286, loss_cls: 0.0481, acc: 99.5312, loss_bbox: 0.1111, loss: 0.2975\n",
      "2023-05-23 14:19:47,001 - mmfewshot - INFO - Iter [740/1200]\tlr: 1.000e-03, eta: 0:01:31, time: 0.193, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0255, loss_rpn_bbox: 0.0396, loss_cls: 0.0607, acc: 99.3359, loss_bbox: 0.0957, loss: 0.2215\n",
      "2023-05-23 14:19:48,926 - mmfewshot - INFO - Iter [750/1200]\tlr: 1.000e-03, eta: 0:01:29, time: 0.192, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.1102, loss_rpn_bbox: 0.0211, loss_cls: 0.0573, acc: 99.0625, loss_bbox: 0.0967, loss: 0.2853\n",
      "2023-05-23 14:19:50,866 - mmfewshot - INFO - Iter [760/1200]\tlr: 1.000e-03, eta: 0:01:27, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0735, loss_rpn_bbox: 0.0235, loss_cls: 0.0468, acc: 99.3359, loss_bbox: 0.1229, loss: 0.2666\n",
      "2023-05-23 14:19:52,808 - mmfewshot - INFO - Iter [770/1200]\tlr: 1.000e-03, eta: 0:01:25, time: 0.194, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.0981, loss_rpn_bbox: 0.0221, loss_cls: 0.0657, acc: 99.3359, loss_bbox: 0.0825, loss: 0.2684\n",
      "2023-05-23 14:19:54,738 - mmfewshot - INFO - Iter [780/1200]\tlr: 1.000e-03, eta: 0:01:23, time: 0.193, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0436, loss_rpn_bbox: 0.0250, loss_cls: 0.0527, acc: 99.1797, loss_bbox: 0.1283, loss: 0.2496\n",
      "2023-05-23 14:19:56,659 - mmfewshot - INFO - Iter [790/1200]\tlr: 1.000e-03, eta: 0:01:21, time: 0.192, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0824, loss_rpn_bbox: 0.0342, loss_cls: 0.0494, acc: 99.3359, loss_bbox: 0.0989, loss: 0.2649\n",
      "2023-05-23 14:19:58,541 - mmfewshot - INFO - Saving checkpoint at 800 iterations\n",
      "2023-05-23 14:19:59,104 - mmfewshot - INFO - Iter [800/1200]\tlr: 1.000e-03, eta: 0:01:19, time: 0.249, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0202, loss_rpn_bbox: 0.0181, loss_cls: 0.0437, acc: 99.6094, loss_bbox: 0.0581, loss: 0.1400\n",
      "2023-05-23 14:20:01,026 - mmfewshot - INFO - Iter [810/1200]\tlr: 1.000e-03, eta: 0:01:17, time: 0.187, data_time: 0.004, memory: 1049, loss_rpn_cls: 0.1773, loss_rpn_bbox: 0.0221, loss_cls: 0.0845, acc: 99.2578, loss_bbox: 0.1125, loss: 0.3964\n",
      "2023-05-23 14:20:02,944 - mmfewshot - INFO - Iter [820/1200]\tlr: 1.000e-03, eta: 0:01:15, time: 0.192, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0570, loss_rpn_bbox: 0.0089, loss_cls: 0.0616, acc: 99.2188, loss_bbox: 0.1157, loss: 0.2431\n",
      "2023-05-23 14:20:04,884 - mmfewshot - INFO - Iter [830/1200]\tlr: 1.000e-03, eta: 0:01:13, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.1535, loss_rpn_bbox: 0.0329, loss_cls: 0.0409, acc: 99.6484, loss_bbox: 0.1349, loss: 0.3621\n",
      "2023-05-23 14:20:06,835 - mmfewshot - INFO - Iter [840/1200]\tlr: 1.000e-03, eta: 0:01:11, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0417, loss_rpn_bbox: 0.0174, loss_cls: 0.0555, acc: 99.1797, loss_bbox: 0.0945, loss: 0.2091\n",
      "2023-05-23 14:20:08,779 - mmfewshot - INFO - Iter [850/1200]\tlr: 1.000e-03, eta: 0:01:09, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0682, loss_rpn_bbox: 0.0226, loss_cls: 0.0277, acc: 99.6094, loss_bbox: 0.0677, loss: 0.1862\n",
      "2023-05-23 14:20:10,717 - mmfewshot - INFO - Iter [860/1200]\tlr: 1.000e-03, eta: 0:01:07, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0833, loss_rpn_bbox: 0.0229, loss_cls: 0.0522, acc: 99.3750, loss_bbox: 0.0844, loss: 0.2429\n",
      "2023-05-23 14:20:12,643 - mmfewshot - INFO - Iter [870/1200]\tlr: 1.000e-03, eta: 0:01:05, time: 0.193, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0398, loss_rpn_bbox: 0.0196, loss_cls: 0.0360, acc: 99.4922, loss_bbox: 0.1389, loss: 0.2343\n",
      "2023-05-23 14:20:14,586 - mmfewshot - INFO - Iter [880/1200]\tlr: 1.000e-03, eta: 0:01:03, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0174, loss_rpn_bbox: 0.0156, loss_cls: 0.0402, acc: 99.3750, loss_bbox: 0.1119, loss: 0.1850\n",
      "2023-05-23 14:20:16,527 - mmfewshot - INFO - Iter [890/1200]\tlr: 1.000e-03, eta: 0:01:01, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0408, loss_rpn_bbox: 0.0330, loss_cls: 0.0768, acc: 99.3750, loss_bbox: 0.0780, loss: 0.2287\n",
      "2023-05-23 14:20:18,460 - mmfewshot - INFO - Iter [900/1200]\tlr: 1.000e-03, eta: 0:00:59, time: 0.193, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.1186, loss_rpn_bbox: 0.0206, loss_cls: 0.0466, acc: 99.5312, loss_bbox: 0.1238, loss: 0.3095\n",
      "2023-05-23 14:20:20,415 - mmfewshot - INFO - Iter [910/1200]\tlr: 1.000e-03, eta: 0:00:57, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.1735, loss_rpn_bbox: 0.0298, loss_cls: 0.0575, acc: 99.2188, loss_bbox: 0.1166, loss: 0.3775\n",
      "2023-05-23 14:20:22,362 - mmfewshot - INFO - Iter [920/1200]\tlr: 1.000e-03, eta: 0:00:55, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0470, loss_rpn_bbox: 0.0315, loss_cls: 0.0459, acc: 99.2578, loss_bbox: 0.1280, loss: 0.2525\n",
      "2023-05-23 14:20:24,293 - mmfewshot - INFO - Iter [930/1200]\tlr: 1.000e-03, eta: 0:00:53, time: 0.193, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.1108, loss_rpn_bbox: 0.0184, loss_cls: 0.0610, acc: 99.6875, loss_bbox: 0.0828, loss: 0.2730\n",
      "2023-05-23 14:20:26,225 - mmfewshot - INFO - Iter [940/1200]\tlr: 1.000e-03, eta: 0:00:51, time: 0.193, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.0843, loss_rpn_bbox: 0.0257, loss_cls: 0.0713, acc: 99.1016, loss_bbox: 0.1375, loss: 0.3188\n",
      "2023-05-23 14:20:28,154 - mmfewshot - INFO - Iter [950/1200]\tlr: 1.000e-03, eta: 0:00:49, time: 0.193, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.1176, loss_rpn_bbox: 0.0225, loss_cls: 0.0326, acc: 99.5312, loss_bbox: 0.1073, loss: 0.2800\n",
      "2023-05-23 14:20:30,090 - mmfewshot - INFO - Iter [960/1200]\tlr: 1.000e-03, eta: 0:00:47, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0317, loss_rpn_bbox: 0.0235, loss_cls: 0.0554, acc: 99.5312, loss_bbox: 0.1000, loss: 0.2105\n",
      "2023-05-23 14:20:32,020 - mmfewshot - INFO - Iter [970/1200]\tlr: 1.000e-03, eta: 0:00:45, time: 0.193, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0901, loss_rpn_bbox: 0.0234, loss_cls: 0.0424, acc: 99.6875, loss_bbox: 0.0850, loss: 0.2409\n",
      "2023-05-23 14:20:33,957 - mmfewshot - INFO - Iter [980/1200]\tlr: 1.000e-03, eta: 0:00:43, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0861, loss_rpn_bbox: 0.0240, loss_cls: 0.0980, acc: 99.0625, loss_bbox: 0.1131, loss: 0.3212\n",
      "2023-05-23 14:20:35,901 - mmfewshot - INFO - Iter [990/1200]\tlr: 1.000e-03, eta: 0:00:41, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0846, loss_rpn_bbox: 0.0317, loss_cls: 0.0630, acc: 98.6328, loss_bbox: 0.1140, loss: 0.2933\n",
      "2023-05-23 14:20:37,819 - mmfewshot - INFO - Exp name: attention-rpn_r50_c4_voc-split1_5shot-fine-tuning.py\n",
      "2023-05-23 14:20:37,819 - mmfewshot - INFO - Iter [1000/1200]\tlr: 1.000e-03, eta: 0:00:39, time: 0.192, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0849, loss_rpn_bbox: 0.0162, loss_cls: 0.0519, acc: 99.3359, loss_bbox: 0.0985, loss: 0.2514\n",
      "2023-05-23 14:20:39,767 - mmfewshot - INFO - Iter [1010/1200]\tlr: 1.000e-03, eta: 0:00:37, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0216, loss_rpn_bbox: 0.0128, loss_cls: 0.0562, acc: 98.9062, loss_bbox: 0.0915, loss: 0.1821\n",
      "2023-05-23 14:20:41,738 - mmfewshot - INFO - Iter [1020/1200]\tlr: 1.000e-03, eta: 0:00:35, time: 0.197, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0400, loss_rpn_bbox: 0.0212, loss_cls: 0.0851, acc: 99.0234, loss_bbox: 0.0821, loss: 0.2285\n",
      "2023-05-23 14:20:43,659 - mmfewshot - INFO - Iter [1030/1200]\tlr: 1.000e-03, eta: 0:00:33, time: 0.192, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.0672, loss_rpn_bbox: 0.0256, loss_cls: 0.0296, acc: 99.6484, loss_bbox: 0.0973, loss: 0.2198\n",
      "2023-05-23 14:20:45,595 - mmfewshot - INFO - Iter [1040/1200]\tlr: 1.000e-03, eta: 0:00:31, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.1127, loss_rpn_bbox: 0.0273, loss_cls: 0.0440, acc: 99.4922, loss_bbox: 0.1356, loss: 0.3196\n",
      "2023-05-23 14:20:47,518 - mmfewshot - INFO - Iter [1050/1200]\tlr: 1.000e-03, eta: 0:00:29, time: 0.192, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0765, loss_rpn_bbox: 0.0220, loss_cls: 0.0615, acc: 99.4141, loss_bbox: 0.0940, loss: 0.2540\n",
      "2023-05-23 14:20:49,460 - mmfewshot - INFO - Iter [1060/1200]\tlr: 1.000e-03, eta: 0:00:27, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0643, loss_rpn_bbox: 0.0229, loss_cls: 0.0276, acc: 99.4531, loss_bbox: 0.1001, loss: 0.2149\n",
      "2023-05-23 14:20:51,371 - mmfewshot - INFO - Iter [1070/1200]\tlr: 1.000e-03, eta: 0:00:25, time: 0.191, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0409, loss_rpn_bbox: 0.0277, loss_cls: 0.0596, acc: 99.6875, loss_bbox: 0.0963, loss: 0.2245\n",
      "2023-05-23 14:20:53,316 - mmfewshot - INFO - Iter [1080/1200]\tlr: 1.000e-03, eta: 0:00:23, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0665, loss_rpn_bbox: 0.0386, loss_cls: 0.0489, acc: 99.6094, loss_bbox: 0.0757, loss: 0.2296\n",
      "2023-05-23 14:20:55,266 - mmfewshot - INFO - Iter [1090/1200]\tlr: 1.000e-03, eta: 0:00:21, time: 0.195, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.1380, loss_rpn_bbox: 0.0325, loss_cls: 0.0754, acc: 99.2188, loss_bbox: 0.1469, loss: 0.3928\n",
      "2023-05-23 14:20:57,179 - mmfewshot - INFO - Iter [1100/1200]\tlr: 1.000e-03, eta: 0:00:19, time: 0.192, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0309, loss_rpn_bbox: 0.0110, loss_cls: 0.0428, acc: 99.6484, loss_bbox: 0.1014, loss: 0.1861\n",
      "2023-05-23 14:20:59,115 - mmfewshot - INFO - Iter [1110/1200]\tlr: 1.000e-03, eta: 0:00:17, time: 0.193, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0773, loss_rpn_bbox: 0.0252, loss_cls: 0.0555, acc: 99.1406, loss_bbox: 0.1416, loss: 0.2997\n",
      "2023-05-23 14:21:01,027 - mmfewshot - INFO - Iter [1120/1200]\tlr: 1.000e-03, eta: 0:00:15, time: 0.191, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.2931, loss_rpn_bbox: 0.0320, loss_cls: 0.0479, acc: 99.1016, loss_bbox: 0.1350, loss: 0.5080\n",
      "2023-05-23 14:21:02,952 - mmfewshot - INFO - Iter [1130/1200]\tlr: 1.000e-03, eta: 0:00:13, time: 0.193, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.1721, loss_rpn_bbox: 0.0192, loss_cls: 0.0305, acc: 99.6094, loss_bbox: 0.0932, loss: 0.3150\n",
      "2023-05-23 14:21:04,894 - mmfewshot - INFO - Iter [1140/1200]\tlr: 1.000e-03, eta: 0:00:11, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0742, loss_rpn_bbox: 0.0368, loss_cls: 0.0447, acc: 99.3750, loss_bbox: 0.0882, loss: 0.2439\n",
      "2023-05-23 14:21:06,850 - mmfewshot - INFO - Iter [1150/1200]\tlr: 1.000e-03, eta: 0:00:09, time: 0.196, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0384, loss_rpn_bbox: 0.0282, loss_cls: 0.0372, acc: 99.6484, loss_bbox: 0.0777, loss: 0.1814\n",
      "2023-05-23 14:21:08,852 - mmfewshot - INFO - Iter [1160/1200]\tlr: 1.000e-03, eta: 0:00:07, time: 0.200, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0348, loss_rpn_bbox: 0.0129, loss_cls: 0.0522, acc: 99.3750, loss_bbox: 0.0899, loss: 0.1898\n",
      "2023-05-23 14:21:10,810 - mmfewshot - INFO - Iter [1170/1200]\tlr: 1.000e-03, eta: 0:00:05, time: 0.196, data_time: 0.010, memory: 1049, loss_rpn_cls: 0.0480, loss_rpn_bbox: 0.0308, loss_cls: 0.0576, acc: 99.4141, loss_bbox: 0.1078, loss: 0.2443\n",
      "2023-05-23 14:21:12,753 - mmfewshot - INFO - Iter [1180/1200]\tlr: 1.000e-03, eta: 0:00:03, time: 0.194, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0784, loss_rpn_bbox: 0.0253, loss_cls: 0.0355, acc: 99.6875, loss_bbox: 0.0658, loss: 0.2051\n",
      "2023-05-23 14:21:14,706 - mmfewshot - INFO - Iter [1190/1200]\tlr: 1.000e-03, eta: 0:00:01, time: 0.195, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.1210, loss_rpn_bbox: 0.0356, loss_cls: 0.0407, acc: 99.2578, loss_bbox: 0.1198, loss: 0.3171\n",
      "2023-05-23 14:21:16,608 - mmfewshot - INFO - Saving checkpoint at 1200 iterations\n",
      "2023-05-23 14:21:17,200 - mmfewshot - INFO - Iter [1200/1200]\tlr: 1.000e-03, eta: 0:00:00, time: 0.254, data_time: 0.009, memory: 1049, loss_rpn_cls: 0.0815, loss_rpn_bbox: 0.0139, loss_cls: 0.0474, acc: 99.5312, loss_bbox: 0.0872, loss: 0.2299\n"
     ]
    }
   ],
   "source": [
    "for data in data_dict:\n",
    "  print(\"Processing data \", data['cat'], \"...\")\n",
    "  create_annotations_and_label_images(data['cat'], data['query_image_path'],\n",
    "                                      data['label_image_path'])\n",
    "  set_category(data['cat'])\n",
    "  add_image_to_txt_path(data['cat'], data['query_image_path'])\n",
    "  command = f\"CUDA_VISIBLE_DEVICES=0 python tools/detection/train.py configs/detection/attention_rpn/voc/split1/attention-rpn_r50_c4_voc-split1_5shot-fine-tuning.py --work-dir {os.path.join(work_dir, data['cat'])} --no-validate\"\n",
    "  print(command)\n",
    "  result = subprocess.run(command, shell=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training time: 7m 42.7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"tools/detection/train.py\", line 237, in <module>\n",
      "    main()\n",
      "  File \"tools/detection/train.py\", line 105, in main\n",
      "    cfg = Config.fromfile(args.config)\n",
      "  File \"/home/tanluuuuuuu/miniconda3/envs/mmfewshot/lib/python3.8/site-packages/mmcv/utils/config.py\", line 340, in fromfile\n",
      "    cfg_dict, cfg_text = Config._file2dict(filename,\n",
      "  File \"/home/tanluuuuuuu/miniconda3/envs/mmfewshot/lib/python3.8/site-packages/mmcv/utils/config.py\", line 183, in _file2dict\n",
      "    check_file_exist(filename)\n",
      "  File \"/home/tanluuuuuuu/miniconda3/envs/mmfewshot/lib/python3.8/site-packages/mmcv/utils/path.py\", line 23, in check_file_exist\n",
      "    raise FileNotFoundError(msg_tmpl.format(filename))\n",
      "FileNotFoundError: file \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/work_dirs/tv_stand_attention-rpn_5shot-fine-tuning/tv_stand_attention-rpn_5shot-fine-tuning.py\" does not exist\n"
     ]
    }
   ],
   "source": [
    "command = f\"CUDA_VISIBLE_DEVICES=0 python tools/detection/train.py /home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/work_dirs/tv_stand_attention-rpn_5shot-fine-tuning/tv_stand_attention-rpn_5shot-fine-tuning.py --no-validate\"\n",
    "result = subprocess.run(command, shell=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['door', '2930', 'kettlebell', '2864', '3190', '3191', '3264', '3326']\n"
     ]
    }
   ],
   "source": [
    "folder_workdir = \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/work_dirs/pipeline_v3/test_default_config_max_object\"\n",
    "print(os.listdir(folder_workdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmfewshot.detection.apis import init_detector, inference_detector\n",
    "import mmcv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "THR = 0.5\n",
    "THR_NMS = 0.2\n",
    "\n",
    "folder_workdir = \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/work_dirs/meta-rcnn\"\n",
    "save_path = \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/result/pipeline_v4/meta-rcnn\"\n",
    "for data in data_dict:\n",
    "  # Specify the path to model config and checkpoint file\n",
    "  config_file = os.path.join(folder_workdir, data['cat'], \"meta-rcnn_r50_c4_8xb4_voc-split1_5shot-fine-tuning.py\")\n",
    "  checkpoint_file = os.path.join(folder_workdir, data['cat'], \"iter_800.pth\")\n",
    "\n",
    "  # build the model from a config file and a checkpoint file\n",
    "  model = init_detector(config_file, checkpoint_file, device='cuda:0')\n",
    "\n",
    "  img_path = data['database_image_path']\n",
    "  cat = data['cat']\n",
    "  # breakpoint()\n",
    "  num_iter = int(checkpoint_file.split(\"/\")[-1].split(\".\")[0].split(\"_\")[1])\n",
    "  folder_name = f\"{cat}_{num_iter}iter_thr{str(int(THR*100))}_nms{str(int(THR_NMS*100))}\"\n",
    "  print(folder_name)\n",
    "  include_path = os.path.join(save_path, folder_name, \"include\")\n",
    "  if not os.path.exists(include_path):\n",
    "    print(f\"Make dir {include_path}\")\n",
    "    os.makedirs(include_path)\n",
    "\n",
    "  exclude_path = os.path.join(save_path, folder_name, \"exclude\")\n",
    "  if not os.path.exists(exclude_path):\n",
    "    print(f\"Make dir {exclude_path}\")\n",
    "    os.makedirs(exclude_path)\n",
    "\n",
    "  sum_time = 0\n",
    "\n",
    "  def nms(boxes):\n",
    "    boxbox = torch.from_numpy(boxes[:, 0:4])\n",
    "    score = torch.from_numpy(boxes[:, 4])\n",
    "    result = torchvision.ops.nms(boxbox, score, THR_NMS)\n",
    "    return result.numpy()\n",
    "\n",
    "  for im_name in tqdm(os.listdir(img_path)[:500]):\n",
    "    img = os.path.join(img_path, im_name)\n",
    "    st = time.time()\n",
    "    try:\n",
    "      result = inference_detector(model, img)\n",
    "    except:\n",
    "      print(im_name)\n",
    "      continue\n",
    "    sum_time += (time.time() - st)\n",
    "    img = cv2.imread(img)\n",
    "    boxes = np.array([box for box in result[-1] if box[4] >= THR])\n",
    "    if len(boxes) > 0:\n",
    "      box_idxs = nms(boxes)\n",
    "      for box in boxes[box_idxs]:\n",
    "        score = box[4]\n",
    "        if score >= THR:\n",
    "          box = box.astype(int)\n",
    "          color = (0, 0, 255)\n",
    "          thickness = 2\n",
    "          img = cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), color, thickness)\n",
    "          img = cv2.putText(img, str(score), (box[0], box[1] + 20), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 1, cv2.LINE_AA)\n",
    "      cv2.imwrite(os.path.join(include_path, im_name), img)\n",
    "    else:\n",
    "      cv2.imwrite(os.path.join(exclude_path, im_name), img)\n",
    "  print(f\"Infer on {len(os.listdir(img_path))} got {sum_time}s\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU RAM inference: 2074MiB\n",
    "\n",
    "Time: 17m 22.1s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISCELLANEOUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# Created by Silencer @ Stackoverflow \n",
    "# 2018.01.23 14:41:42 CST\n",
    "# 2018.01.23 18:17:42 CST\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "## (1) Convert to gray, and threshold\n",
    "img = cv2.imread(\"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/photo_2023-04-11_08-17-05.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "th, threshed = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "## (2) Morph-op to remove noise\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
    "morphed = cv2.morphologyEx(threshed, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "## (3) Find the max-area contour\n",
    "cnts = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "cnt = sorted(cnts, key=cv2.contourArea)[-1]\n",
    "\n",
    "## (4) Crop and save it\n",
    "x,y,w,h = cv2.boundingRect(cnt)\n",
    "# dst = img[y:y+h, x:x+w]\n",
    "color = (255, 0, 0)\n",
    "thickness = 1\n",
    "img = cv2.rectangle(img, (y, x), (y+h, x+w), color, thickness)\n",
    "cv2.imshow(\"img.jpg\", img)\n",
    "# cv2.imwrite(\"001.png\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "folder1 = \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/result/pipeline_v2/fine_tune_v0/door_new_bbox_4500iter_thr20/include\"\n",
    "folder2 = \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/result/pipeline_v2/fine_tune_v0/door_new_bbox_4500iter_th10_nms40/include\"\n",
    "\n",
    "list_1 = os.listdir(folder1)\n",
    "list_2 = os.listdir(folder2)\n",
    "\n",
    "diff_folder = \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/result/pipeline_v2/diff_20_10\"\n",
    "\n",
    "list_diff = list(set(list_2) - set(list_1))\n",
    "for im in list_diff:\n",
    "    source = os.path.join(folder2, im)\n",
    "    dest = os.path.join(diff_folder, im)\n",
    "    shutil.copy(source, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = map(int, input().split())\n",
    "def recur(a, b):\n",
    "    if b == 0:\n",
    "        return a\n",
    "    return recur(b, b % a)\n",
    "c = recur(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/work_dirs/pipeline_v3/test_default_config_max_object/door/iter_4500.pth\n",
      "[array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([], shape=(0, 5), dtype=float32), array([[  0.       ,  16.0888   , 237.56364  , 249.24487  ,   0.9340162]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "from mmfewshot.detection.apis import init_detector, inference_detector\n",
    "import cv2\n",
    "\n",
    "config_file = \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/work_dirs/pipeline_v3/test_default_config_max_object/door/fsce_r101_fpn_contrastive-loss_voc-split1_5shot-fine-tuning.py\"\n",
    "checkpoint_file = \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/work_dirs/pipeline_v3/test_default_config_max_object/door/iter_4500.pth\"\n",
    "\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')\n",
    "# print(model)\n",
    "img_path = \"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/result/door_attention_rpn/exclude/B096LGD5BR.jpg\"\n",
    "result = inference_detector(model, img_path)\n",
    "print(result)\n",
    "# img = cv2.imread(img_path)\n",
    "# print(img.shape)\n",
    "# for box in result[-1]:\n",
    "#   if box[-1] >= 0.5:\n",
    "#     box = list(map(int, box))\n",
    "#     print(box)\n",
    "#     cropped = img[box[1]:box[3], box[0]:box[2]]\n",
    "#     cv2.imwrite(\"001.png\", cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 250, 3)\n",
      "(250, 250, 3)\n",
      "[155 182 203]\n",
      "[143 166 181]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img1 = cv2.imread(\"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/mmfewshot/result/attention_rpn/door_40thr_attention_rpn/exclude/B0BKTFJ5SY.jpg\")\n",
    "img2 = cv2.imread(\"/home/tanluuuuuuu/Desktop/luunvt/image_retrieval/data/img/door/B0BKTFJ5SY.jpg\")\n",
    "print(img1.shape)\n",
    "print(img2.shape)\n",
    "print(img1[0][0])\n",
    "print(img2[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmfewshot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2089cf5fb82f7c9ed8e960b0a74486a18e89933162b9e2b46e49851fa4e1e0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
